{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import torch # PyToch library for building and training neural networks\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import numpy as np # for numerical calculations\n",
    "from collections import namedtuple, deque # provides useful data structures may not need\n",
    "import random # for random sampling \n",
    "from mss import mss # for grabbing a screen shot of a monitor \n",
    "import pydirectinput # for mouse and keyboard input on windows\n",
    "import cv2 as cv # for image and video processing\n",
    "import pytesseract # OCR tool for reading text from images\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import time\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "from gymnasium.utils import env_checker  # Import the environment checker\n",
    "from collections import deque\n",
    "\n",
    "def plot_learning_curve(x, scores, epsilons, filename, lines=None):\n",
    "\tfig=plt.figure()\n",
    "\tax=fig.add_subplot(111, label=\"1\")\n",
    "\tax2=fig.add_subplot(111, label=\"2\", frame_on=False)\n",
    "\n",
    "\tax.plot(x, epsilons, color=\"C0\")\n",
    "\tax.set_xlabel(\"Training Steps\", color=\"C0\")\n",
    "\tax.set_ylabel(\"Epsilon\", color=\"C0\")\n",
    "\tax.tick_params(axis='x', colors=\"C0\")\n",
    "\tax.tick_params(axis='y', colors=\"C0\")\n",
    "\n",
    "\tN = len(scores)\n",
    "\trunning_avg = np.empty(N)\n",
    "\tfor t in range(N):\n",
    "\t\trunning_avg[t] = np.mean(scores[max(0, t-20):(t+1)])\n",
    "\n",
    "\tax2.scatter(x, running_avg, color=\"C1\")\n",
    "\tax2.axes.get_xaxis().set_visible(False)\n",
    "\tax2.yaxis.tick_right()\n",
    "\tax2.set_ylabel('Score', color=\"C1\")\n",
    "\tax2.yaxis.set_label_position('right')\n",
    "\tax2.tick_params(axis='y', colors=\"C1\")\n",
    "\n",
    "\tif lines is not None:\n",
    "\t\tfor line in lines:\n",
    "\t\t\tplt.axvline(x=line)\n",
    "\n",
    "\tplt.savefig(filename)\n",
    "\n",
    "\n",
    "# Designing DQN Model\n",
    "class DQN(nn.Module): # defines a new neural network model that inherits from Pytorch's base class nn.module\n",
    "\tdef __init__(self, lr, input_dims, fc1_dims, fc2_dims, num_actions): \n",
    "\t\tsuper(DQN, self).__init__() # calls the initializer of the parent class nn.module \n",
    "\t\tself.input_dims = input_dims\n",
    "\t\tself.fc1_dims = fc1_dims\n",
    "\t\tself.fc2_dims = fc2_dims\n",
    "\t\tself.conv1 = nn.Conv2d(self.input_dims[0], 32, kernel_size=8, stride=4) # convolutional layer with 32 filters, each of size 8 x8, applied with a stride of 4\n",
    "\t\tself.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2) # convolutional layer with 64 filters, each of size 4 x 4, applied with a stride of 2\n",
    "\t\tself.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1) # convolutional layer with 64 filters, each of size 3 x 3\n",
    "\t\tself.fc_input_size = self._calculate_fc_input_size(self.input_dims)\n",
    "\t\tself.fc1 = nn.Linear(self.fc_input_size, self.fc1_dims) # fully connected layer with 512 units\n",
    "\t\tself.fc2 = nn.Linear(self.fc2_dims, num_actions) # final fully connected layer with output units equal to the number of possible actions\n",
    "\t\tself.optimizer = Adam(self.parameters(), lr=lr)\n",
    "\t\tself.loss = nn.MSELoss()\n",
    "\t\tself.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\t\tself.to(self.device)\n",
    "\t\t\n",
    "\tdef _calculate_fc_input_size(self, input_dims):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tdummy_input = torch.zeros(1, input_dims[0], 50, 80)\n",
    "\t\t\tx = torch.relu(self.conv1(dummy_input))\n",
    "\t\t\tx = torch.relu(self.conv2(x))\n",
    "\t\t\tx = torch.relu(self.conv3(x))\n",
    "\t\t\t\n",
    "\t\t\treturn x.view(1, -1).size(1)  # Flatten and get the size\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\tx = torch.relu(self.conv1(x))\n",
    "\t\tx = torch.relu(self.conv2(x))\n",
    "\t\tx = torch.relu(self.conv3(x))\n",
    "\t\tx = x.view(x.size(0), -1) # Flatten the output from conv layers\n",
    "\t\tx = torch.relu(self.fc1(x))\n",
    "\t\tactions =  self.fc2(x)  # Output Q-Values for each action\n",
    "\t\t\n",
    "\t\treturn actions\n",
    "\t\n",
    "# Creating Replay Buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_mem_size, input_dims):\n",
    "        self.mem_size = max_mem_size \n",
    "        self.mem_cntr = 0\n",
    "        self.state_memory = np.zeros((self.mem_size, *input_dims), dtype=np.float32)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *input_dims), dtype=np.float32)\n",
    "        self.action_memory = np.zeros(self.mem_size, dtype=np.int32)\n",
    "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool_)\n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        index = self.mem_cntr % self.mem_size\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.reward_memory[index] = reward\n",
    "        self.action_memory[index] = action\n",
    "        self.terminal_memory[index] = done\n",
    "        self.mem_cntr += 1\n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "        batch =random.sample(range(max_mem), batch_size)\n",
    "        states = self.state_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        new_states = self.new_state_memory[batch]\n",
    "        dones = self.terminal_memory[batch]\n",
    "        return states, actions, rewards, new_states, dones\n",
    "  \n",
    "# Creating DQN Agent\n",
    "class DQNAgent:       \n",
    "\tdef __init__(self, gamma, epsilon, lr, input_dims, batch_size, num_actions,\n",
    "\t\t\t\t max_mem_size=10000, eps_end=0.01, eps_dec=0.99, replace_target=1000):\n",
    "\t\tself.gamma = gamma # Determines the weighting of future rewards\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.epsilon_end = eps_end\n",
    "\t\tself.epsilon_decay = eps_dec\n",
    "\t\tself.lr = lr\n",
    "\t\tself.action_space = [i for i in range(num_actions)]\n",
    "\t\tself.num_actions = num_actions\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.replace_target = replace_target # Number of steps before updating target network\n",
    "\t\tself.learn_step_counter = 0 # Track the steps for target network update\n",
    "\t\t\n",
    "\t\t# Initialize evaluation (q_eval) and target (q_target) network\n",
    "\t\tself.q_eval = DQN(self.lr, input_dims, fc1_dims=512, fc2_dims=512, num_actions=num_actions)\n",
    "\t\tself.q_target = DQN(self.lr, input_dims, fc1_dims=512, fc2_dims=512, num_actions=num_actions)\n",
    "  \n",
    "\t\t# Initially, the target network has the same weights as the evaluation network\n",
    "\t\tself.q_target.load_state_dict(self.q_eval.state_dict())\n",
    "\t\tself.q_target.eval()\n",
    "  \n",
    "\t\t# Initialize the replay buffer\n",
    "\t\tself.memory = ReplayBuffer(max_mem_size, input_dims)\n",
    "\t\tself.optimizer = Adam(self.q_eval.parameters(), lr=self.lr)\n",
    "\t\tself.loss = nn.MSELoss()\n",
    "\t\tself.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\tdef store_transition(self, state, action, reward, state_, done):\n",
    "\t\tself.memory.store_transition(state, action, reward, state_, done)\n",
    "  \n",
    "\t# Method for choosing an action\n",
    "\tdef choose_action(self, observation):\n",
    "\t\tif np.random.random() > self.epsilon:\n",
    "\t\t\tobservation = observation / 255.0\n",
    "\t\t\tstate = torch.tensor([observation], dtype=torch.float32).to(self.q_eval.device)\n",
    "\t\t\tactions = self.q_eval.forward(state)\n",
    "\t\t\taction = torch.argmax(actions).item()\n",
    "\t\telse:\n",
    "\t\t\taction = np.random.choice(self.action_space)\n",
    "\t\treturn action\n",
    "\n",
    "\tdef replace_target_network(self):\n",
    "\t\tif self.learn_step_counter % self.replace_target == 0:\n",
    "\t\t\tself.q_target.load_state_dict(self.q_eval.state_dict())\n",
    "\t\t\tprint('Target network updated.')\n",
    "\t\n",
    "\tdef learn(self):\n",
    "\t\tif self.memory.mem_cntr < self.batch_size:\n",
    "\t\t\treturn\n",
    "\t\tself.optimizer.zero_grad()\n",
    "\t\t\n",
    "\t\tself.replace_target_network()\n",
    "  \n",
    "\t\tstates, actions, rewards, states_, dones = self.memory.sample_buffer(self.batch_size)\n",
    "\t\t\n",
    "\t\tstates = torch.tensor(states).to(self.q_eval.device)\n",
    "\t\trewards = torch.tensor(rewards).to(self.q_eval.device)\n",
    "\t\tdones = torch.tensor(dones, dtype=torch.float32).to(self.q_eval.device)\n",
    "\t\tactions = torch.tensor(actions).to(self.q_eval.device)\n",
    "\t\tstates_ = torch.tensor(states_).to(self.q_eval.device)\n",
    "\t\t\n",
    "\t\t# Q-values for the next state from the target network (for stability)\n",
    "\t\tq_next = self.q_target.forward(states_).max(dim=1)[0]\n",
    "\n",
    "\t\t# Q-values for current state from evaluation network\n",
    "\t\tq_pred = self.q_eval.forward(states)[range(self.batch_size), actions]\n",
    "\t\t\n",
    "\t\t# Calculate target Q-values using Bellman equation\n",
    "\t\tq_target = rewards + self.gamma *  q_next * (1 - dones)\n",
    "\t\t\n",
    "\t\t# Compute loss between predicted Q-values and target Q-values\n",
    "\t\tloss = self.loss(q_pred, q_target)\n",
    "\t\tloss.backward()\n",
    "\t\tself.optimizer.step()\n",
    "\n",
    "\t\t# Increment the step counter\t\t\n",
    "\t\tself.learn_step_counter += 1\n",
    "  \n",
    "\t\treturn loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Environment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import torch # PyToch library for building and training neural networks\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "import numpy as np # for numerical calculations\n",
    "from collections import namedtuple, deque # provides useful data structures may not need\n",
    "import random # for random sampling \n",
    "from mss import mss # for grabbing a screen shot of a monitor \n",
    "import pydirectinput # for mouse and keyboard input on windows\n",
    "import cv2 as cv # for image and video processing\n",
    "import pytesseract # OCR tool for reading text from images\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import time\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "from gymnasium.utils.env_checker import check_env  # Import the environment checker\n",
    "from collections import deque\n",
    "import math\n",
    "\n",
    "\n",
    "class PacMan(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define spaces\n",
    "        self.observation_space = Box(low=0, high=255, shape=(6,50,80), dtype=np.uint8)\n",
    "        self.action_space = Discrete(4) # number of possible actions\n",
    "        \n",
    "        # Define capture locations\n",
    "        self.cap = mss()\n",
    "        self.game_location = {'top':50, 'left':-2280, 'width':1400, 'height':1300}# defines game viewing location\n",
    "        self.lives_location = {'top':1070, 'left':-902, 'width':600, 'height':200} # defines lives location\n",
    "        self.frame_stack = deque(maxlen=6) # stack frames to provide a sense of motion\n",
    "        #self.score_location = {'top':380, 'left':-920, 'width':600, 'height':80} # defines score location\n",
    "        #self.done_location = {'top':508, 'left':-1810, 'width':450, 'height':80} \n",
    "            \n",
    "        # Define lives\n",
    "        self.previous_lives = 2\n",
    "        self.current_lives = self.previous_lives\n",
    "        self.previous_score = 0\n",
    "        self.time_alive = 0\n",
    "        self.last_life = 2\n",
    "        self.survival_reward_factor = 0.01\n",
    "        \n",
    "        # Define pellet count\n",
    "        self.pellet_address = 0x7268 # ROM memory address\n",
    "        self.file_path = \"pellet_count.txt\" # file to store value\n",
    "        self.previous_pellet_count = self.read_pellet_count_from_file()\n",
    "        \n",
    "\n",
    "        # Define templates for tracking\n",
    "        self.ghost_template = cv.imread('C:\\\\Users\\\\John Wesley\\\\Docs\\\\PacMan\\\\PacManGame\\\\Images\\\\ghost_template.png', 0)\n",
    "        self.ghost_template2 = cv.imread('C:\\\\Users\\\\John Wesley\\\\Docs\\\\PacMan\\\\PacManGame\\\\Images\\\\ghost_template3.png', 0)\n",
    "        self.ghost_template3 = cv.imread('C:\\\\Users\\\\John Wesley\\\\Docs\\\\PacMan\\\\PacManGame\\\\Images\\\\ghost_template4.png', 0)\n",
    "        self.pacman_life_template = cv.imread('C:\\\\Users\\\\John Wesley\\\\Docs\\\\PacMan\\\\PacManGame\\\\Images\\\\pacman_life_icon.png', 0)\n",
    "        self.pacman_template_left = cv.imread('C:\\\\Users\\\\John Wesley\\\\Docs\\\\PacMan\\\\PacManGame\\\\Images\\\\pacman_template_left.png', 0)\n",
    "        self.pacman_template_right = cv.imread('C:\\\\Users\\\\John Wesley\\\\Docs\\\\PacMan\\\\PacManGame\\\\Images\\\\pacman_template_right.png', 0)\n",
    "        self.pacman_template_up = cv.imread('C:\\\\Users\\\\John Wesley\\\\Docs\\\\PacMan\\\\PacManGame\\\\Images\\\\pacman_template_up.png', 0)\n",
    "        self.pacman_template_down = cv.imread('C:\\\\Users\\\\John Wesley\\\\Docs\\\\PacMan\\\\PacManGame\\\\Images\\\\pacman_template_down.png', 0)\n",
    "        self.pacman_template_closed = cv.imread('C:\\\\Users\\\\John Wesley\\\\Docs\\\\PacMan\\\\PacManGame\\\\Images\\\\pacman_template_closed.png', 0)\n",
    "        \n",
    "    # Observation of the state of the environment\n",
    "    def get_observation(self):\n",
    "        # Get screen capture of game\n",
    "        raw = np.array(self.cap.grab(self.game_location))[:,:,:3]\n",
    "        # Grayscale\n",
    "        gray = cv.cvtColor(raw, cv.COLOR_BGR2GRAY)\n",
    "        # Resize\n",
    "        resized = cv.resize(gray, (80,50))\n",
    "        # Add channels first\n",
    "        channel = np.reshape(resized, (1,50,80))\n",
    "        return channel\n",
    "    \n",
    "    def get_stacked_observation(self):\n",
    "        # Stack the frames in the deque and convert to the required shape\n",
    "        return np.concatenate(list(self.frame_stack), axis=0)\n",
    "    \n",
    "    # Get number of lives left\n",
    "    def get_lives(self):   \n",
    "        # Capture the area where the lives are displayed\n",
    "        lives_cap = np.array(self.cap.grab(self.lives_location))[:,:,:3]\n",
    "        # Convert to grayscale\n",
    "        lives_gray = cv.cvtColor(lives_cap, cv.COLOR_BGR2GRAY)\n",
    "        # Perform template matching\n",
    "        result = cv.matchTemplate(lives_gray, self.pacman_life_template, cv.TM_CCORR_NORMED)\n",
    "        locations = np.where(result >= 0.8) # find areas that have values at or above threshold value\n",
    "        lives_value = len(list(zip(*locations[::-1])))\n",
    "        \n",
    "        # Determine number of lives\n",
    "        if lives_value == 684:\n",
    "            num_lives = 2 \n",
    "        elif lives_value == 344:\n",
    "            num_lives = 1\n",
    "        else:\n",
    "            num_lives = 0\n",
    "            \n",
    "        return num_lives\n",
    "    \n",
    "    # Get game over\n",
    "    def get_done(self):\n",
    "        # Get the number of lives left \n",
    "        num_lives = self.get_lives()\n",
    "        return num_lives == 0 # return bool\n",
    "    \n",
    "    # Get pellet count\n",
    "    def read_pellet_count_from_file(self):\n",
    "        try:\n",
    "            with open(self.file_path, \"r\") as file:\n",
    "                return int(file.read().strip())\n",
    "        except (FileNotFoundError, ValueError):\n",
    "            return 0\n",
    "        \n",
    "    # Resets the environment to its initial state\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        # restart the game\n",
    "        pydirectinput.click(x=-890, y=374) # Select game window\n",
    "        pydirectinput.press('f1') # Start state 1 save\n",
    "        # Reset pellet count\n",
    "        self.previous_pellet_count = self.read_pellet_count_from_file()\n",
    "        # Reset frame stack\n",
    "        self.frame_stack.clear() # Delete all items from Deque\n",
    "        # Update deque with reset state\n",
    "        for _ in range(6):\n",
    "            initial_frame = self.get_observation()\n",
    "            self.frame_stack.append(initial_frame)\n",
    "            \n",
    "        return self.get_stacked_observation(), {}\n",
    "    \n",
    "    # Rendering method to see what the computer sees\n",
    "    def render(self):\n",
    "        frame = self.render_positions()\n",
    "        cv.imshow('Game', frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            self.close()\n",
    "            \n",
    "    # Closes rendering window        \n",
    "    def close(self):\n",
    "        cv.destroyAllWindows()\n",
    "    \n",
    "    # Find character locations on screen            \n",
    "    def get_character_positions(self):\n",
    "        screen_capture = np.array(self.cap.grab(self.game_location))[:,:,:3]\n",
    "        cv.imwrite('game_capture.png', screen_capture)\n",
    "        # Convert to grayscale\n",
    "        gray_screen = cv.cvtColor(screen_capture, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Match the templates to find Pac-Man and Ghosts\n",
    "        result_left = cv.matchTemplate(gray_screen, self.pacman_template_left, cv.TM_CCOEFF_NORMED)\n",
    "        result_right = cv.matchTemplate(gray_screen, self.pacman_template_right, cv.TM_CCOEFF_NORMED)\n",
    "        result_up = cv.matchTemplate(gray_screen, self.pacman_template_up, cv.TM_CCOEFF_NORMED)\n",
    "        result_down = cv.matchTemplate(gray_screen, self.pacman_template_down, cv.TM_CCOEFF_NORMED)\n",
    "        result_closed = cv.matchTemplate(gray_screen, self.pacman_template_closed, cv.TM_CCOEFF_NORMED)\n",
    "        result_ghost = cv.matchTemplate(gray_screen, self.ghost_template, cv.TM_CCOEFF_NORMED)\n",
    "        result_ghost2 = cv.matchTemplate(gray_screen, self.ghost_template2, cv.TM_CCOEFF_NORMED)\n",
    "        result_ghost3 = cv.matchTemplate(gray_screen, self.ghost_template3, cv.TM_CCOEFF_NORMED)\n",
    "        \n",
    "        # Locate pacman\n",
    "        pacman_threshold = 0.6 # Adjust this value based on testing\n",
    "        locations_left = np.where(result_left >= pacman_threshold)\n",
    "        locations_right = np.where(result_right >= pacman_threshold)\n",
    "        locations_up = np.where(result_up >= pacman_threshold)\n",
    "        locations_down = np.where(result_down >= pacman_threshold)\n",
    "        locations_closed = np.where(result_closed >= pacman_threshold)\n",
    "        \n",
    "        # Locate ghosts\n",
    "        ghost_threshold = 0.5\n",
    "        location_ghost = np.where(result_ghost >= ghost_threshold)\n",
    "        location_ghost2 = np.where(result_ghost2 >= ghost_threshold)\n",
    "        location_ghost3 = np.where(result_ghost3 >= ghost_threshold)\n",
    "        \n",
    "        # Pack locations\n",
    "        pacman_combined_locations = list(zip(*locations_left[::-1])) + list(zip(*locations_right[::-1])) + list(zip(*locations_up[::-1])) + list(zip(*locations_down[::-1])) + list(zip(*locations_closed[::-1]))\n",
    "        ghost_position = list(zip(*location_ghost[::-1])) + list(zip(*location_ghost2[::-1]))  + list(zip(*location_ghost3[::-1]))\n",
    "\n",
    "        return ghost_position, pacman_combined_locations, screen_capture\n",
    "    \n",
    "    # Method to see character detection    \n",
    "    def render_positions(self):\n",
    "        # Get character positions\n",
    "        ghost_position, pacman_combined_locations, screen_capture = self.get_character_positions()\n",
    "\n",
    "        screen_capture = np.ascontiguousarray(screen_capture) # convert captured image to OpenCV compatability\n",
    "        \n",
    "        # Draw rectangles around matched Pac-Man locations using OpenCV\n",
    "        for loc in pacman_combined_locations:\n",
    "            top_left = loc\n",
    "            bottom_right = (top_left[0] + self.pacman_template_right.shape[1], top_left[1] + self.pacman_template_right.shape[0])\n",
    "            # Create a rectangle patch and add it to the plot\n",
    "            cv.rectangle(screen_capture, top_left, bottom_right, (255, 0, 0), 2)\n",
    "            \n",
    "        # Draw rectangles around matched Ghost locations using OpenCV\n",
    "        for loc in ghost_position:\n",
    "            top_left = loc\n",
    "            bottom_right = (top_left[0] + self.ghost_template.shape[1], top_left[1] + self.ghost_template.shape[0])\n",
    "            # Create a rectangle patch and add it to the plot\n",
    "            cv.rectangle(screen_capture, top_left, bottom_right, (0, 0, 255), 2)\n",
    "\n",
    "        # cv.imshow('Test Render positions', screen_capture)\n",
    "        # cv.waitKey(0)\n",
    "        # cv.destroyAllWindows()\n",
    "        return screen_capture\n",
    "    \n",
    "    def calculate_distance (self, pacman_pos, ghost_pos):\n",
    "        # Unpack positions\n",
    "        pacman_x, pacman_y = pacman_pos\n",
    "        ghost_x, ghost_y = ghost_pos\n",
    "        return math.sqrt((ghost_x - pacman_x) ** 2 + (ghost_y - pacman_y) ** 2)\n",
    "    \n",
    "    # Calculate reward for eating pellets\n",
    "    def get_pellet_reward(self, current_pellet_count):\n",
    "        if current_pellet_count < self.previous_pellet_count:\n",
    "            reward = 20\n",
    "            self.previous_pellet_count = current_pellet_count\n",
    "        else:\n",
    "            reward = 0    \n",
    "        return reward\n",
    "    \n",
    "    def ghost_avoidance_reward(self):\n",
    "        ghost_positions, pacman_combined_locations, _ = self.get_character_positions()\n",
    "        if pacman_combined_locations:\n",
    "            pacman_pos = pacman_combined_locations[0]\n",
    "        else:\n",
    "            pacman_pos = (0, 0)\n",
    "        safe_distance = 260\n",
    "        avoidance_reward = 0\n",
    "        num_considered_ghosts = min(len(ghost_positions), 4)\n",
    "        \n",
    "        for ghost_pos in ghost_positions[:num_considered_ghosts]:\n",
    "            distance = self.calculate_distance(pacman_pos, ghost_pos)\n",
    "            #print(f\"Ghost {ghost_index + 1} Position: {ghost_pos}, Distance: {distance}\")\n",
    "            if distance > safe_distance:\n",
    "                # avoidance_reward += (distance - safe_distance)\n",
    "                avoidance_reward += 20 / num_considered_ghosts\n",
    "            else:\n",
    "                # avoidance_reward -= (safe_distance - distance) * 2\n",
    "                avoidance_reward -= 10\n",
    "        return avoidance_reward\n",
    "    \n",
    "    # Method that is called to do something in the game\n",
    "    def step(self, action):\n",
    "        action_map = {\n",
    "            0: 'left',   # Move Left\n",
    "            1: 'right',  # Move Right\n",
    "            2: 'up',     # Move Up\n",
    "            3: 'down',   # Move Down\n",
    "        }\n",
    "        \n",
    "        pydirectinput.press(action_map[action])\n",
    "        \n",
    "        # Reward for eating pellets \n",
    "        # current_pellet_count = self.read_pellet_count_from_file()\n",
    "        # pellet_reward = self.get_pellet_reward(current_pellet_count)\n",
    "        # Reward for avoiding ghosts\n",
    "        avoidance_reward = self.ghost_avoidance_reward()\n",
    "        # Bonus reward for staying alive      \n",
    "        current_lives = self.get_lives()\n",
    "        # if current_lives < self.last_life:\n",
    "        #     self.time_alive = 0\n",
    "        #     self.last_life = current_lives\n",
    "        # self.time_alive += 1\n",
    "        # # survival_reward = self.survival_reward_factor * (1.1 ** self.time_alive)\n",
    "        # survival_reward = self.time_alive * 1.01 \n",
    "        # Penalize only when a life is lost (and only once per life loss)\n",
    "        life_penalty = 0\n",
    "        if current_lives < self.previous_lives:\n",
    "            life_penalty -= 40\n",
    "            self.previous_lives = current_lives # update previous lives \n",
    "           \n",
    "        reward = avoidance_reward + life_penalty \n",
    "        \n",
    "        done = self.get_done()\n",
    "        \n",
    "        # Get the next observation\n",
    "        new_frame = self.get_observation()\n",
    "        self.frame_stack.append(new_frame)\n",
    "        stacked_observation = self.get_stacked_observation()\n",
    "        \n",
    "        return stacked_observation, reward, done, False, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = PacMan()\n",
    "\n",
    "# check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| episodes   |   0    |\n",
      "| score      |  213.73 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   1    |\n",
      "| score      |  433.52000000000004 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   2    |\n",
      "| score      |  415.53 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   3    |\n",
      "| score      |  578.14 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   4    |\n",
      "| score      |  1164.9099999999999 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   5    |\n",
      "| score      |  1304.64 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   6    |\n",
      "| score      |  1232.4100000000003 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   7    |\n",
      "| score      |  1510.3700000000001 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   8    |\n",
      "| score      |  1475.0200000000002 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   9    |\n",
      "| score      |  894.26 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   10    |\n",
      "| score      |  1986.9899999999996 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   11    |\n",
      "| score      |  2024.4600000000003 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   12    |\n",
      "| score      |  2855.6899999999996 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   13    |\n",
      "| score      |  2378.3600000000006 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   14    |\n",
      "| score      |  2489.0499999999997 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   15    |\n",
      "| score      |  4330.3 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   16    |\n",
      "| score      |  3557.8500000000004 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   17    |\n",
      "| score      |  4029.52 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   18    |\n",
      "| score      |  3171.8200000000006 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   19    |\n",
      "| score      |  3277.2599999999998 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   20    |\n",
      "| score      |  3704.4900000000007 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      "\n",
      "Target network updated.\n",
      "------------------------\n",
      "| episodes   |   21    |\n",
      "| score      |  3266.35 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      ", loss 26781.1719\n",
      "------------------------\n",
      "| episodes   |   22    |\n",
      "| score      |  5744.910000000001 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      ", loss 28551.2617\n",
      "------------------------\n",
      "| episodes   |   23    |\n",
      "| score      |  3871.74 |\n",
      "| epsilon    |  1.00   |\n",
      "------------------------\n",
      ", loss 19749.0508\n",
      "------------------------\n",
      "| episodes   |   24    |\n",
      "| score      |  3287.5500000000006 |\n",
      "| epsilon    |  0.99   |\n",
      "------------------------\n",
      ", loss 15213.2461\n",
      "------------------------\n",
      "| episodes   |   25    |\n",
      "| score      |  6040.63 |\n",
      "| epsilon    |  0.99   |\n",
      "------------------------\n",
      ", loss 9680.8242\n",
      "------------------------\n",
      "| episodes   |   26    |\n",
      "| score      |  5212.630000000001 |\n",
      "| epsilon    |  0.99   |\n",
      "------------------------\n",
      ", loss 19145.3750\n",
      "------------------------\n",
      "| episodes   |   27    |\n",
      "| score      |  6231.120000000001 |\n",
      "| epsilon    |  0.99   |\n",
      "------------------------\n",
      ", loss 16554.1953\n",
      "------------------------\n",
      "| episodes   |   28    |\n",
      "| score      |  7326.57 |\n",
      "| epsilon    |  0.99   |\n",
      "------------------------\n",
      ", loss 14524.0850\n",
      "------------------------\n",
      "| episodes   |   29    |\n",
      "| score      |  6700.56 |\n",
      "| epsilon    |  0.98   |\n",
      "------------------------\n",
      ", loss 27983.3281\n",
      "------------------------\n",
      "| episodes   |   30    |\n",
      "| score      |  6067.59 |\n",
      "| epsilon    |  0.98   |\n",
      "------------------------\n",
      ", loss 20467.8438\n",
      "Model saved as saved_models/best_pacman_dqn_model_30.pth\n",
      "------------------------\n",
      "| episodes   |   31    |\n",
      "| score      |  3490.36 |\n",
      "| epsilon    |  0.98   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   32    |\n",
      "| score      |  6841.15 |\n",
      "| epsilon    |  0.98   |\n",
      "------------------------\n",
      ", loss 23449.8477\n",
      "------------------------\n",
      "| episodes   |   33    |\n",
      "| score      |  7168.400000000001 |\n",
      "| epsilon    |  0.98   |\n",
      "------------------------\n",
      ", loss 17988.1934\n",
      "------------------------\n",
      "| episodes   |   34    |\n",
      "| score      |  5330.59 |\n",
      "| epsilon    |  0.98   |\n",
      "------------------------\n",
      ", loss 20414.5234\n",
      "------------------------\n",
      "| episodes   |   35    |\n",
      "| score      |  8513.11 |\n",
      "| epsilon    |  0.97   |\n",
      "------------------------\n",
      ", loss 22089.9141\n",
      "------------------------\n",
      "| episodes   |   36    |\n",
      "| score      |  10410.300000000001 |\n",
      "| epsilon    |  0.97   |\n",
      "------------------------\n",
      ", loss 24379.7383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John Wesley\\AppData\\Local\\Temp\\ipykernel_21556\\2200964324.py:150: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  state = torch.tensor([observation], dtype=torch.float32).to(self.q_eval.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| episodes   |   37    |\n",
      "| score      |  8655.12 |\n",
      "| epsilon    |  0.97   |\n",
      "------------------------\n",
      ", loss 30751.9707\n",
      "------------------------\n",
      "| episodes   |   38    |\n",
      "| score      |  6081.63 |\n",
      "| epsilon    |  0.97   |\n",
      "------------------------\n",
      ", loss 26103.9297\n",
      "------------------------\n",
      "| episodes   |   39    |\n",
      "| score      |  9591.990000000002 |\n",
      "| epsilon    |  0.97   |\n",
      "------------------------\n",
      ", loss 27264.4688\n",
      "------------------------\n",
      "| episodes   |   40    |\n",
      "| score      |  9903.88 |\n",
      "| epsilon    |  0.96   |\n",
      "------------------------\n",
      ", loss 37264.1406\n",
      "Model saved as saved_models/best_pacman_dqn_model_40.pth\n",
      "------------------------\n",
      "| episodes   |   41    |\n",
      "| score      |  10871.67 |\n",
      "| epsilon    |  0.96   |\n",
      "------------------------\n",
      ", loss 38200.8477\n",
      "------------------------\n",
      "| episodes   |   42    |\n",
      "| score      |  11753.999999999998 |\n",
      "| epsilon    |  0.96   |\n",
      "------------------------\n",
      ", loss 34859.8672\n",
      "------------------------\n",
      "| episodes   |   43    |\n",
      "| score      |  7012.650000000001 |\n",
      "| epsilon    |  0.96   |\n",
      "------------------------\n",
      ", loss 34875.9258\n",
      "------------------------\n",
      "| episodes   |   44    |\n",
      "| score      |  11624.310000000001 |\n",
      "| epsilon    |  0.96   |\n",
      "------------------------\n",
      ", loss 39322.3047\n",
      "------------------------\n",
      "| episodes   |   45    |\n",
      "| score      |  10677.440000000002 |\n",
      "| epsilon    |  0.95   |\n",
      "------------------------\n",
      ", loss 41439.4531\n",
      "------------------------\n",
      "| episodes   |   46    |\n",
      "| score      |  13062.160000000002 |\n",
      "| epsilon    |  0.95   |\n",
      "------------------------\n",
      ", loss 37816.3984\n",
      "------------------------\n",
      "| episodes   |   47    |\n",
      "| score      |  12667.85 |\n",
      "| epsilon    |  0.95   |\n",
      "------------------------\n",
      ", loss 47684.0117\n",
      "------------------------\n",
      "| episodes   |   48    |\n",
      "| score      |  14430.300000000001 |\n",
      "| epsilon    |  0.95   |\n",
      "------------------------\n",
      ", loss 41420.7305\n",
      "------------------------\n",
      "| episodes   |   49    |\n",
      "| score      |  12472.400000000001 |\n",
      "| epsilon    |  0.95   |\n",
      "------------------------\n",
      ", loss 45351.8750\n",
      "------------------------\n",
      "| episodes   |   50    |\n",
      "| score      |  10619.97 |\n",
      "| epsilon    |  0.95   |\n",
      "------------------------\n",
      ", loss 40767.4922\n",
      "Model saved as saved_models/best_pacman_dqn_model_50.pth\n",
      "------------------------\n",
      "| episodes   |   51    |\n",
      "| score      |  11602.499999999998 |\n",
      "| epsilon    |  0.94   |\n",
      "------------------------\n",
      ", loss 58053.3906\n",
      "------------------------\n",
      "| episodes   |   52    |\n",
      "| score      |  9268.62 |\n",
      "| epsilon    |  0.94   |\n",
      "------------------------\n",
      ", loss 52099.1016\n",
      "------------------------\n",
      "| episodes   |   53    |\n",
      "| score      |  9454.06 |\n",
      "| epsilon    |  0.94   |\n",
      "------------------------\n",
      ", loss 50694.8047\n",
      "------------------------\n",
      "| episodes   |   54    |\n",
      "| score      |  13794.300000000001 |\n",
      "| epsilon    |  0.94   |\n",
      "------------------------\n",
      ", loss 69278.0625\n",
      "------------------------\n",
      "| episodes   |   55    |\n",
      "| score      |  11609.770000000002 |\n",
      "| epsilon    |  0.94   |\n",
      "------------------------\n",
      ", loss 61680.1250\n",
      "------------------------\n",
      "| episodes   |   56    |\n",
      "| score      |  10953.47 |\n",
      "| epsilon    |  0.93   |\n",
      "------------------------\n",
      ", loss 62981.2227\n",
      "------------------------\n",
      "| episodes   |   57    |\n",
      "| score      |  10939.16 |\n",
      "| epsilon    |  0.93   |\n",
      "------------------------\n",
      ", loss 65921.2734\n",
      "------------------------\n",
      "| episodes   |   58    |\n",
      "| score      |  11274.85 |\n",
      "| epsilon    |  0.93   |\n",
      "------------------------\n",
      ", loss 64480.9180\n",
      "------------------------\n",
      "| episodes   |   59    |\n",
      "| score      |  12194.19 |\n",
      "| epsilon    |  0.93   |\n",
      "------------------------\n",
      ", loss 59069.4258\n",
      "------------------------\n",
      "| episodes   |   60    |\n",
      "| score      |  16078.41 |\n",
      "| epsilon    |  0.93   |\n",
      "------------------------\n",
      ", loss 83823.4844\n",
      "Model saved as saved_models/best_pacman_dqn_model_60.pth\n",
      "------------------------\n",
      "| episodes   |   61    |\n",
      "| score      |  14646.64 |\n",
      "| epsilon    |  0.92   |\n",
      "------------------------\n",
      ", loss 70061.6719\n",
      "------------------------\n",
      "| episodes   |   62    |\n",
      "| score      |  14865.2 |\n",
      "| epsilon    |  0.92   |\n",
      "------------------------\n",
      ", loss 69818.2734\n",
      "------------------------\n",
      "| episodes   |   63    |\n",
      "| score      |  15163.76 |\n",
      "| epsilon    |  0.92   |\n",
      "------------------------\n",
      ", loss 77507.3516\n",
      "------------------------\n",
      "| episodes   |   64    |\n",
      "| score      |  20249.820000000003 |\n",
      "| epsilon    |  0.92   |\n",
      "------------------------\n",
      ", loss 79372.8125\n",
      "------------------------\n",
      "| episodes   |   65    |\n",
      "| score      |  17780.07 |\n",
      "| epsilon    |  0.92   |\n",
      "------------------------\n",
      ", loss 83732.4219\n",
      "------------------------\n",
      "| episodes   |   66    |\n",
      "| score      |  13008.009999999998 |\n",
      "| epsilon    |  0.92   |\n",
      "------------------------\n",
      ", loss 86071.6875\n",
      "------------------------\n",
      "| episodes   |   67    |\n",
      "| score      |  21292.739999999998 |\n",
      "| epsilon    |  0.91   |\n",
      "------------------------\n",
      ", loss 82567.9375\n",
      "------------------------\n",
      "| episodes   |   68    |\n",
      "| score      |  18690.43 |\n",
      "| epsilon    |  0.91   |\n",
      "------------------------\n",
      ", loss 86958.8750\n",
      "------------------------\n",
      "| episodes   |   69    |\n",
      "| score      |  17982.27 |\n",
      "| epsilon    |  0.91   |\n",
      "------------------------\n",
      ", loss 85515.5000\n",
      "------------------------\n",
      "| episodes   |   70    |\n",
      "| score      |  19256.73 |\n",
      "| epsilon    |  0.91   |\n",
      "------------------------\n",
      ", loss 86930.1328\n",
      "Model saved as saved_models/best_pacman_dqn_model_70.pth\n",
      "------------------------\n",
      "| episodes   |   71    |\n",
      "| score      |  18583.220000000005 |\n",
      "| epsilon    |  0.91   |\n",
      "------------------------\n",
      ", loss 94626.8281\n",
      "------------------------\n",
      "| episodes   |   72    |\n",
      "| score      |  18795.110000000004 |\n",
      "| epsilon    |  0.90   |\n",
      "------------------------\n",
      ", loss 108577.6016\n",
      "------------------------\n",
      "| episodes   |   73    |\n",
      "| score      |  15632.79 |\n",
      "| epsilon    |  0.90   |\n",
      "------------------------\n",
      ", loss 77747.0938\n",
      "------------------------\n",
      "| episodes   |   74    |\n",
      "| score      |  15950.749999999998 |\n",
      "| epsilon    |  0.90   |\n",
      "------------------------\n",
      ", loss 115956.7969\n",
      "------------------------\n",
      "| episodes   |   75    |\n",
      "| score      |  25519.71 |\n",
      "| epsilon    |  0.90   |\n",
      "------------------------\n",
      ", loss 128729.1406\n",
      "------------------------\n",
      "| episodes   |   76    |\n",
      "| score      |  19985.5 |\n",
      "| epsilon    |  0.90   |\n",
      "------------------------\n",
      ", loss 112766.7422\n",
      "------------------------\n",
      "| episodes   |   77    |\n",
      "| score      |  23838.7 |\n",
      "| epsilon    |  0.90   |\n",
      "------------------------\n",
      ", loss 126826.0781\n",
      "------------------------\n",
      "| episodes   |   78    |\n",
      "| score      |  13314.240000000002 |\n",
      "| epsilon    |  0.89   |\n",
      "------------------------\n",
      ", loss 130804.8672\n",
      "------------------------\n",
      "| episodes   |   79    |\n",
      "| score      |  24569.899999999998 |\n",
      "| epsilon    |  0.89   |\n",
      "------------------------\n",
      ", loss 161931.7812\n",
      "------------------------\n",
      "| episodes   |   80    |\n",
      "| score      |  16091.08 |\n",
      "| epsilon    |  0.89   |\n",
      "------------------------\n",
      ", loss 129247.1484\n",
      "Model saved as saved_models/best_pacman_dqn_model_80.pth\n",
      "------------------------\n",
      "| episodes   |   81    |\n",
      "| score      |  20084.879999999997 |\n",
      "| epsilon    |  0.89   |\n",
      "------------------------\n",
      ", loss 151165.2031\n",
      "------------------------\n",
      "| episodes   |   82    |\n",
      "| score      |  21630.989999999998 |\n",
      "| epsilon    |  0.89   |\n",
      "------------------------\n",
      ", loss 122028.9531\n",
      "------------------------\n",
      "| episodes   |   83    |\n",
      "| score      |  15409.379999999997 |\n",
      "| epsilon    |  0.89   |\n",
      "------------------------\n",
      ", loss 185162.5000\n",
      "------------------------\n",
      "| episodes   |   84    |\n",
      "| score      |  16867.62 |\n",
      "| epsilon    |  0.88   |\n",
      "------------------------\n",
      ", loss 161350.7031\n",
      "------------------------\n",
      "| episodes   |   85    |\n",
      "| score      |  22332.129999999997 |\n",
      "| epsilon    |  0.88   |\n",
      "------------------------\n",
      ", loss 150300.1562\n",
      "------------------------\n",
      "| episodes   |   86    |\n",
      "| score      |  22644.019999999997 |\n",
      "| epsilon    |  0.88   |\n",
      "------------------------\n",
      ", loss 166302.2812\n",
      "------------------------\n",
      "| episodes   |   87    |\n",
      "| score      |  17464.73 |\n",
      "| epsilon    |  0.88   |\n",
      "------------------------\n",
      ", loss 178115.2188\n",
      "------------------------\n",
      "| episodes   |   88    |\n",
      "| score      |  13398.250000000002 |\n",
      "| epsilon    |  0.88   |\n",
      "------------------------\n",
      ", loss 160203.4844\n",
      "------------------------\n",
      "| episodes   |   89    |\n",
      "| score      |  17846.72 |\n",
      "| epsilon    |  0.87   |\n",
      "------------------------\n",
      ", loss 146823.8750\n",
      "------------------------\n",
      "| episodes   |   90    |\n",
      "| score      |  12296.949999999999 |\n",
      "| epsilon    |  0.87   |\n",
      "------------------------\n",
      ", loss 177538.2656\n",
      "Model saved as saved_models/best_pacman_dqn_model_90.pth\n",
      "------------------------\n",
      "| episodes   |   91    |\n",
      "| score      |  16669.86 |\n",
      "| epsilon    |  0.87   |\n",
      "------------------------\n",
      ", loss 173733.2969\n",
      "------------------------\n",
      "| episodes   |   92    |\n",
      "| score      |  25342.489999999998 |\n",
      "| epsilon    |  0.87   |\n",
      "------------------------\n",
      ", loss 205459.2500\n",
      "------------------------\n",
      "| episodes   |   93    |\n",
      "| score      |  18429.48 |\n",
      "| epsilon    |  0.87   |\n",
      "------------------------\n",
      ", loss 180184.9062\n",
      "------------------------\n",
      "| episodes   |   94    |\n",
      "| score      |  25901.07 |\n",
      "| epsilon    |  0.87   |\n",
      "------------------------\n",
      ", loss 161822.8906\n",
      "------------------------\n",
      "| episodes   |   95    |\n",
      "| score      |  21834.2 |\n",
      "| epsilon    |  0.86   |\n",
      "------------------------\n",
      ", loss 163549.6875\n",
      "------------------------\n",
      "| episodes   |   96    |\n",
      "| score      |  25033.480000000003 |\n",
      "| epsilon    |  0.86   |\n",
      "------------------------\n",
      ", loss 171511.0000\n",
      "------------------------\n",
      "| episodes   |   97    |\n",
      "| score      |  23816.68 |\n",
      "| epsilon    |  0.86   |\n",
      "------------------------\n",
      ", loss 205364.2500\n",
      "------------------------\n",
      "| episodes   |   98    |\n",
      "| score      |  18030.940000000002 |\n",
      "| epsilon    |  0.86   |\n",
      "------------------------\n",
      ", loss 206899.5312\n",
      "------------------------\n",
      "| episodes   |   99    |\n",
      "| score      |  28913.100000000006 |\n",
      "| epsilon    |  0.86   |\n",
      "------------------------\n",
      ", loss 170637.3281\n",
      "------------------------\n",
      "| episodes   |   100    |\n",
      "| score      |  29157.71 |\n",
      "| epsilon    |  0.86   |\n",
      "------------------------\n",
      ", loss 223833.2500\n",
      "Model saved as saved_models/best_pacman_dqn_model_100.pth\n",
      "------------------------\n",
      "| episodes   |   101    |\n",
      "| score      |  24928.24 |\n",
      "| epsilon    |  0.85   |\n",
      "------------------------\n",
      ", loss 179219.3438\n",
      "------------------------\n",
      "| episodes   |   102    |\n",
      "| score      |  18730.86 |\n",
      "| epsilon    |  0.85   |\n",
      "------------------------\n",
      ", loss 249142.7031\n",
      "------------------------\n",
      "| episodes   |   103    |\n",
      "| score      |  30159.640000000003 |\n",
      "| epsilon    |  0.85   |\n",
      "------------------------\n",
      ", loss 235001.5938\n",
      "------------------------\n",
      "| episodes   |   104    |\n",
      "| score      |  27305.579999999998 |\n",
      "| epsilon    |  0.85   |\n",
      "------------------------\n",
      ", loss 204985.2500\n",
      "------------------------\n",
      "| episodes   |   105    |\n",
      "| score      |  19312.62 |\n",
      "| epsilon    |  0.85   |\n",
      "------------------------\n",
      ", loss 273389.9688\n",
      "------------------------\n",
      "| episodes   |   106    |\n",
      "| score      |  29451.629999999997 |\n",
      "| epsilon    |  0.85   |\n",
      "------------------------\n",
      ", loss 238078.7812\n",
      "------------------------\n",
      "| episodes   |   107    |\n",
      "| score      |  26277.280000000002 |\n",
      "| epsilon    |  0.84   |\n",
      "------------------------\n",
      ", loss 276447.3750\n",
      "------------------------\n",
      "| episodes   |   108    |\n",
      "| score      |  26620.84 |\n",
      "| epsilon    |  0.84   |\n",
      "------------------------\n",
      ", loss 392516.9375\n",
      "------------------------\n",
      "| episodes   |   109    |\n",
      "| score      |  28642.01 |\n",
      "| epsilon    |  0.84   |\n",
      "------------------------\n",
      ", loss 250295.6250\n",
      "------------------------\n",
      "| episodes   |   110    |\n",
      "| score      |  22045.840000000004 |\n",
      "| epsilon    |  0.84   |\n",
      "------------------------\n",
      ", loss 366480.6250\n",
      "Model saved as saved_models/best_pacman_dqn_model_110.pth\n",
      "------------------------\n",
      "| episodes   |   111    |\n",
      "| score      |  27429.199999999997 |\n",
      "| epsilon    |  0.84   |\n",
      "------------------------\n",
      ", loss 218962.2812\n",
      "------------------------\n",
      "| episodes   |   112    |\n",
      "| score      |  29451.829999999998 |\n",
      "| epsilon    |  0.84   |\n",
      "------------------------\n",
      ", loss 242600.0625\n",
      "------------------------\n",
      "| episodes   |   113    |\n",
      "| score      |  22704.82 |\n",
      "| epsilon    |  0.83   |\n",
      "------------------------\n",
      ", loss 372727.9375\n",
      "------------------------\n",
      "| episodes   |   114    |\n",
      "| score      |  28172.56 |\n",
      "| epsilon    |  0.83   |\n",
      "------------------------\n",
      ", loss 273977.8125\n",
      "------------------------\n",
      "| episodes   |   115    |\n",
      "| score      |  26541.600000000002 |\n",
      "| epsilon    |  0.83   |\n",
      "------------------------\n",
      ", loss 219395.4375\n",
      "------------------------\n",
      "| episodes   |   116    |\n",
      "| score      |  30484.200000000004 |\n",
      "| epsilon    |  0.83   |\n",
      "------------------------\n",
      ", loss 220547.3438\n",
      "------------------------\n",
      "| episodes   |   117    |\n",
      "| score      |  28843.24 |\n",
      "| epsilon    |  0.83   |\n",
      "------------------------\n",
      ", loss 285936.0312\n",
      "------------------------\n",
      "| episodes   |   118    |\n",
      "| score      |  29226.8 |\n",
      "| epsilon    |  0.83   |\n",
      "------------------------\n",
      ", loss 245574.8594\n",
      "------------------------\n",
      "| episodes   |   119    |\n",
      "| score      |  29465.359999999997 |\n",
      "| epsilon    |  0.82   |\n",
      "------------------------\n",
      ", loss 261289.4688\n",
      "------------------------\n",
      "| episodes   |   120    |\n",
      "| score      |  29743.92 |\n",
      "| epsilon    |  0.82   |\n",
      "------------------------\n",
      ", loss 254941.9219\n",
      "Model saved as saved_models/best_pacman_dqn_model_120.pth\n",
      "------------------------\n",
      "| episodes   |   121    |\n",
      "| score      |  20460.18 |\n",
      "| epsilon    |  0.82   |\n",
      "------------------------\n",
      ", loss 265900.5312\n",
      "------------------------\n",
      "| episodes   |   122    |\n",
      "| score      |  28222.65 |\n",
      "| epsilon    |  0.82   |\n",
      "------------------------\n",
      ", loss 228202.3438\n",
      "------------------------\n",
      "| episodes   |   123    |\n",
      "| score      |  28509.899999999998 |\n",
      "| epsilon    |  0.82   |\n",
      "------------------------\n",
      ", loss 277393.5312\n",
      "------------------------\n",
      "| episodes   |   124    |\n",
      "| score      |  32613.94 |\n",
      "| epsilon    |  0.82   |\n",
      "------------------------\n",
      ", loss 282379.3125\n",
      "------------------------\n",
      "| episodes   |   125    |\n",
      "| score      |  30939.76 |\n",
      "| epsilon    |  0.81   |\n",
      "------------------------\n",
      ", loss 329512.0625\n",
      "------------------------\n",
      "| episodes   |   126    |\n",
      "| score      |  31198.32 |\n",
      "| epsilon    |  0.81   |\n",
      "------------------------\n",
      ", loss 309568.6875\n",
      "------------------------\n",
      "| episodes   |   127    |\n",
      "| score      |  43212.37000000001 |\n",
      "| epsilon    |  0.81   |\n",
      "------------------------\n",
      ", loss 338505.4375\n",
      "------------------------\n",
      "| episodes   |   128    |\n",
      "| score      |  31792.399999999998 |\n",
      "| epsilon    |  0.81   |\n",
      "------------------------\n",
      ", loss 315623.9375\n",
      "------------------------\n",
      "| episodes   |   129    |\n",
      "| score      |  42099.91 |\n",
      "| epsilon    |  0.81   |\n",
      "------------------------\n",
      ", loss 287727.8750\n",
      "------------------------\n",
      "| episodes   |   130    |\n",
      "| score      |  32330.32 |\n",
      "| epsilon    |  0.81   |\n",
      "------------------------\n",
      ", loss 332453.3125\n",
      "Model saved as saved_models/best_pacman_dqn_model_130.pth\n",
      "------------------------\n",
      "| episodes   |   131    |\n",
      "| score      |  26392.52 |\n",
      "| epsilon    |  0.80   |\n",
      "------------------------\n",
      ", loss 320642.8750\n",
      "------------------------\n",
      "| episodes   |   132    |\n",
      "| score      |  28767.449999999997 |\n",
      "| epsilon    |  0.80   |\n",
      "------------------------\n",
      ", loss 397621.0000\n",
      "------------------------\n",
      "| episodes   |   133    |\n",
      "| score      |  16410.280000000002 |\n",
      "| epsilon    |  0.80   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   134    |\n",
      "| score      |  24806.62 |\n",
      "| epsilon    |  0.80   |\n",
      "------------------------\n",
      ", loss 306314.8750\n",
      "------------------------\n",
      "| episodes   |   135    |\n",
      "| score      |  28988.21 |\n",
      "| epsilon    |  0.80   |\n",
      "------------------------\n",
      ", loss 291655.5625\n",
      "------------------------\n",
      "| episodes   |   136    |\n",
      "| score      |  37887.15 |\n",
      "| epsilon    |  0.80   |\n",
      "------------------------\n",
      ", loss 299442.9375\n",
      "------------------------\n",
      "| episodes   |   137    |\n",
      "| score      |  35909.45 |\n",
      "| epsilon    |  0.80   |\n",
      "------------------------\n",
      ", loss 270552.6875\n",
      "------------------------\n",
      "| episodes   |   138    |\n",
      "| score      |  38503.450000000004 |\n",
      "| epsilon    |  0.79   |\n",
      "------------------------\n",
      ", loss 328522.3438\n",
      "------------------------\n",
      "| episodes   |   139    |\n",
      "| score      |  36630.399999999994 |\n",
      "| epsilon    |  0.79   |\n",
      "------------------------\n",
      ", loss 502070.9375\n",
      "------------------------\n",
      "| episodes   |   140    |\n",
      "| score      |  30375.97 |\n",
      "| epsilon    |  0.79   |\n",
      "------------------------\n",
      ", loss 421602.2500\n",
      "Model saved as saved_models/best_pacman_dqn_model_140.pth\n",
      "------------------------\n",
      "| episodes   |   141    |\n",
      "| score      |  32752.499999999996 |\n",
      "| epsilon    |  0.79   |\n",
      "------------------------\n",
      ", loss 428084.8125\n",
      "------------------------\n",
      "| episodes   |   142    |\n",
      "| score      |  33039.75 |\n",
      "| epsilon    |  0.79   |\n",
      "------------------------\n",
      ", loss 372739.3125\n",
      "------------------------\n",
      "| episodes   |   143    |\n",
      "| score      |  33222.0 |\n",
      "| epsilon    |  0.79   |\n",
      "------------------------\n",
      ", loss 397695.6875\n",
      "------------------------\n",
      "| episodes   |   144    |\n",
      "| score      |  17787.32 |\n",
      "| epsilon    |  0.78   |\n",
      "------------------------\n",
      ", loss 500455.5000\n",
      "------------------------\n",
      "| episodes   |   145    |\n",
      "| score      |  28937.260000000002 |\n",
      "| epsilon    |  0.78   |\n",
      "------------------------\n",
      ", loss 366541.5938\n",
      "------------------------\n",
      "| episodes   |   146    |\n",
      "| score      |  38325.89 |\n",
      "| epsilon    |  0.78   |\n",
      "------------------------\n",
      ", loss 441404.1250\n",
      "------------------------\n",
      "| episodes   |   147    |\n",
      "| score      |  36353.36 |\n",
      "| epsilon    |  0.78   |\n",
      "------------------------\n",
      ", loss 370700.1250\n",
      "------------------------\n",
      "| episodes   |   148    |\n",
      "| score      |  31873.79 |\n",
      "| epsilon    |  0.78   |\n",
      "------------------------\n",
      ", loss 554123.3125\n",
      "------------------------\n",
      "| episodes   |   149    |\n",
      "| score      |  29880.060000000005 |\n",
      "| epsilon    |  0.78   |\n",
      "------------------------\n",
      ", loss 501983.7812\n",
      "------------------------\n",
      "| episodes   |   150    |\n",
      "| score      |  25344.14 |\n",
      "| epsilon    |  0.78   |\n",
      "------------------------\n",
      ", loss 493676.0000\n",
      "Model saved as saved_models/best_pacman_dqn_model_150.pth\n",
      "------------------------\n",
      "| episodes   |   151    |\n",
      "| score      |  37226.0 |\n",
      "| epsilon    |  0.77   |\n",
      "------------------------\n",
      ", loss 426817.7500\n",
      "------------------------\n",
      "| episodes   |   152    |\n",
      "| score      |  44447.950000000004 |\n",
      "| epsilon    |  0.77   |\n",
      "------------------------\n",
      ", loss 431692.8750\n",
      "------------------------\n",
      "| episodes   |   153    |\n",
      "| score      |  40165.91 |\n",
      "| epsilon    |  0.77   |\n",
      "------------------------\n",
      ", loss 400181.9688\n",
      "------------------------\n",
      "| episodes   |   154    |\n",
      "| score      |  38006.32 |\n",
      "| epsilon    |  0.77   |\n",
      "------------------------\n",
      ", loss 421464.5625\n",
      "------------------------\n",
      "| episodes   |   155    |\n",
      "| score      |  40712.52 |\n",
      "| epsilon    |  0.77   |\n",
      "------------------------\n",
      ", loss 465514.3750\n",
      "------------------------\n",
      "| episodes   |   156    |\n",
      "| score      |  43220.23 |\n",
      "| epsilon    |  0.77   |\n",
      "------------------------\n",
      ", loss 495233.1250\n",
      "------------------------\n",
      "| episodes   |   157    |\n",
      "| score      |  24173.75 |\n",
      "| epsilon    |  0.76   |\n",
      "------------------------\n",
      ", loss 437296.5625\n",
      "------------------------\n",
      "| episodes   |   158    |\n",
      "| score      |  43939.27 |\n",
      "| epsilon    |  0.76   |\n",
      "------------------------\n",
      ", loss 417266.0938\n",
      "------------------------\n",
      "| episodes   |   159    |\n",
      "| score      |  29387.98 |\n",
      "| epsilon    |  0.76   |\n",
      "------------------------\n",
      ", loss 446676.3438\n",
      "------------------------\n",
      "| episodes   |   160    |\n",
      "| score      |  42020.27 |\n",
      "| epsilon    |  0.76   |\n",
      "------------------------\n",
      ", loss 586990.3750\n",
      "Model saved as saved_models/best_pacman_dqn_model_160.pth\n",
      "------------------------\n",
      "| episodes   |   161    |\n",
      "| score      |  44813.73 |\n",
      "| epsilon    |  0.76   |\n",
      "------------------------\n",
      ", loss 422315.5625\n",
      "------------------------\n",
      "| episodes   |   162    |\n",
      "| score      |  37524.75 |\n",
      "| epsilon    |  0.76   |\n",
      "------------------------\n",
      ", loss 410838.7500\n",
      "------------------------\n",
      "| episodes   |   163    |\n",
      "| score      |  42798.77 |\n",
      "| epsilon    |  0.76   |\n",
      "------------------------\n",
      ", loss 360890.1250\n",
      "------------------------\n",
      "| episodes   |   164    |\n",
      "| score      |  40619.6 |\n",
      "| epsilon    |  0.75   |\n",
      "------------------------\n",
      ", loss 539220.2500\n",
      "------------------------\n",
      "| episodes   |   165    |\n",
      "| score      |  38251.950000000004 |\n",
      "| epsilon    |  0.75   |\n",
      "------------------------\n",
      ", loss 474393.5625\n",
      "------------------------\n",
      "| episodes   |   166    |\n",
      "| score      |  28178.86 |\n",
      "| epsilon    |  0.75   |\n",
      "------------------------\n",
      ", loss 541581.5000\n",
      "------------------------\n",
      "| episodes   |   167    |\n",
      "| score      |  38645.85 |\n",
      "| epsilon    |  0.75   |\n",
      "------------------------\n",
      ", loss 542428.0625\n",
      "------------------------\n",
      "| episodes   |   168    |\n",
      "| score      |  49349.64 |\n",
      "| epsilon    |  0.75   |\n",
      "------------------------\n",
      ", loss 506260.4688\n",
      "------------------------\n",
      "| episodes   |   169    |\n",
      "| score      |  54936.960000000014 |\n",
      "| epsilon    |  0.75   |\n",
      "------------------------\n",
      ", loss 554146.1250\n",
      "------------------------\n",
      "| episodes   |   170    |\n",
      "| score      |  44816.149999999994 |\n",
      "| epsilon    |  0.75   |\n",
      "------------------------\n",
      ", loss 537804.8750\n",
      "Model saved as saved_models/best_pacman_dqn_model_170.pth\n",
      "------------------------\n",
      "| episodes   |   171    |\n",
      "| score      |  34469.3 |\n",
      "| epsilon    |  0.74   |\n",
      "------------------------\n",
      ", loss 568223.8125\n",
      "------------------------\n",
      "| episodes   |   172    |\n",
      "| score      |  48051.59 |\n",
      "| epsilon    |  0.74   |\n",
      "------------------------\n",
      ", loss 498178.9375\n",
      "------------------------\n",
      "| episodes   |   173    |\n",
      "| score      |  32142.859999999993 |\n",
      "| epsilon    |  0.74   |\n",
      "------------------------\n",
      ", loss 666994.7500\n",
      "------------------------\n",
      "| episodes   |   174    |\n",
      "| score      |  8063.4400000000005 |\n",
      "| epsilon    |  0.74   |\n",
      "------------------------\n",
      "\n",
      "------------------------\n",
      "| episodes   |   175    |\n",
      "| score      |  21400.280000000002 |\n",
      "| epsilon    |  0.74   |\n",
      "------------------------\n",
      ", loss 770211.6250\n",
      "------------------------\n",
      "| episodes   |   176    |\n",
      "| score      |  43254.48 |\n",
      "| epsilon    |  0.74   |\n",
      "------------------------\n",
      ", loss 716124.5000\n",
      "------------------------\n",
      "| episodes   |   177    |\n",
      "| score      |  46329.939999999995 |\n",
      "| epsilon    |  0.74   |\n",
      "------------------------\n",
      ", loss 716537.1250\n",
      "------------------------\n",
      "| episodes   |   178    |\n",
      "| score      |  41114.700000000004 |\n",
      "| epsilon    |  0.73   |\n",
      "------------------------\n",
      ", loss 555294.5000\n",
      "------------------------\n",
      "| episodes   |   179    |\n",
      "| score      |  35808.56 |\n",
      "| epsilon    |  0.73   |\n",
      "------------------------\n",
      ", loss 908512.5000\n",
      "------------------------\n",
      "| episodes   |   180    |\n",
      "| score      |  33180.939999999995 |\n",
      "| epsilon    |  0.73   |\n",
      "------------------------\n",
      ", loss 645932.1250\n",
      "Model saved as saved_models/best_pacman_dqn_model_180.pth\n",
      "------------------------\n",
      "| episodes   |   181    |\n",
      "| score      |  44534.159999999996 |\n",
      "| epsilon    |  0.73   |\n",
      "------------------------\n",
      ", loss 596994.1250\n",
      "------------------------\n",
      "| episodes   |   182    |\n",
      "| score      |  41963.1 |\n",
      "| epsilon    |  0.73   |\n",
      "------------------------\n",
      ", loss 648772.8750\n",
      "------------------------\n",
      "| episodes   |   183    |\n",
      "| score      |  36543.84 |\n",
      "| epsilon    |  0.73   |\n",
      "------------------------\n",
      ", loss 619822.3750\n",
      "------------------------\n",
      "| episodes   |   184    |\n",
      "| score      |  36654.53 |\n",
      "| epsilon    |  0.73   |\n",
      "------------------------\n",
      ", loss 715769.0000\n",
      "------------------------\n",
      "| episodes   |   185    |\n",
      "| score      |  48227.32 |\n",
      "| epsilon    |  0.72   |\n",
      "------------------------\n",
      ", loss 700063.0000\n",
      "------------------------\n",
      "| episodes   |   186    |\n",
      "| score      |  42761.8 |\n",
      "| epsilon    |  0.72   |\n",
      "------------------------\n",
      ", loss 701297.5000\n",
      "------------------------\n",
      "| episodes   |   187    |\n",
      "| score      |  48776.76 |\n",
      "| epsilon    |  0.72   |\n",
      "------------------------\n",
      ", loss 543662.5000\n",
      "------------------------\n",
      "| episodes   |   188    |\n",
      "| score      |  49108.649999999994 |\n",
      "| epsilon    |  0.72   |\n",
      "------------------------\n",
      ", loss 762621.2500\n",
      "------------------------\n",
      "| episodes   |   189    |\n",
      "| score      |  37751.8 |\n",
      "| epsilon    |  0.72   |\n",
      "------------------------\n",
      ", loss 612612.7500\n",
      "------------------------\n",
      "| episodes   |   190    |\n",
      "| score      |  37862.490000000005 |\n",
      "| epsilon    |  0.72   |\n",
      "------------------------\n",
      ", loss 680965.1250\n",
      "Model saved as saved_models/best_pacman_dqn_model_190.pth\n",
      "------------------------\n",
      "| episodes   |   191    |\n",
      "| score      |  61656.9 |\n",
      "| epsilon    |  0.72   |\n",
      "------------------------\n",
      ", loss 901385.0625\n",
      "------------------------\n",
      "| episodes   |   192    |\n",
      "| score      |  70959.0 |\n",
      "| epsilon    |  0.71   |\n",
      "------------------------\n",
      ", loss 761080.7500\n",
      "------------------------\n",
      "| episodes   |   193    |\n",
      "| score      |  50544.61 |\n",
      "| epsilon    |  0.71   |\n",
      "------------------------\n",
      ", loss 565145.5000\n",
      "------------------------\n",
      "| episodes   |   194    |\n",
      "| score      |  38927.24 |\n",
      "| epsilon    |  0.71   |\n",
      "------------------------\n",
      ", loss 590665.1250\n",
      "------------------------\n",
      "| episodes   |   195    |\n",
      "| score      |  48133.99999999999 |\n",
      "| epsilon    |  0.71   |\n",
      "------------------------\n",
      ", loss 562785.6250\n",
      "------------------------\n",
      "| episodes   |   196    |\n",
      "| score      |  54467.310000000005 |\n",
      "| epsilon    |  0.71   |\n",
      "------------------------\n",
      ", loss 746100.3750\n",
      "------------------------\n",
      "| episodes   |   197    |\n",
      "| score      |  45569.4 |\n",
      "| epsilon    |  0.71   |\n",
      "------------------------\n",
      ", loss 624453.3125\n",
      "------------------------\n",
      "| episodes   |   198    |\n",
      "| score      |  39721.3 |\n",
      "| epsilon    |  0.71   |\n",
      "------------------------\n",
      ", loss 561330.0625\n",
      "------------------------\n",
      "| episodes   |   199    |\n",
      "| score      |  42952.29 |\n",
      "| epsilon    |  0.70   |\n",
      "------------------------\n",
      ", loss 598207.5625\n",
      "------------------------\n",
      "| episodes   |   200    |\n",
      "| score      |  49362.159999999996 |\n",
      "| epsilon    |  0.70   |\n",
      "------------------------\n",
      ", loss 773889.0000\n",
      "Model saved as saved_models/best_pacman_dqn_model_200.pth\n",
      "------------------------\n",
      "| episodes   |   201    |\n",
      "| score      |  55848.99 |\n",
      "| epsilon    |  0.70   |\n",
      "------------------------\n",
      ", loss 763024.5000\n",
      "------------------------\n",
      "| episodes   |   202    |\n",
      "| score      |  56176.229999999996 |\n",
      "| epsilon    |  0.70   |\n",
      "------------------------\n",
      ", loss 624359.6250\n",
      "------------------------\n",
      "| episodes   |   203    |\n",
      "| score      |  50102.48 |\n",
      "| epsilon    |  0.70   |\n",
      "------------------------\n",
      ", loss 676845.8750\n",
      "------------------------\n",
      "| episodes   |   204    |\n",
      "| score      |  40928.65 |\n",
      "| epsilon    |  0.70   |\n",
      "------------------------\n",
      ", loss 658724.8125\n",
      "------------------------\n",
      "| episodes   |   205    |\n",
      "| score      |  60191.99 |\n",
      "| epsilon    |  0.70   |\n",
      "------------------------\n",
      ", loss 785223.9375\n",
      "------------------------\n",
      "| episodes   |   206    |\n",
      "| score      |  44444.25 |\n",
      "| epsilon    |  0.69   |\n",
      "------------------------\n",
      ", loss 800330.8125\n",
      "------------------------\n",
      "| episodes   |   207    |\n",
      "| score      |  57610.630000000005 |\n",
      "| epsilon    |  0.69   |\n",
      "------------------------\n",
      ", loss 864115.0000\n",
      "------------------------\n",
      "| episodes   |   208    |\n",
      "| score      |  38502.22 |\n",
      "| epsilon    |  0.69   |\n",
      "------------------------\n",
      ", loss 770740.0625\n",
      "------------------------\n",
      "| episodes   |   209    |\n",
      "| score      |  64646.9 |\n",
      "| epsilon    |  0.69   |\n",
      "------------------------\n",
      ", loss 837720.7500\n",
      "------------------------\n",
      "| episodes   |   210    |\n",
      "| score      |  61684.76 |\n",
      "| epsilon    |  0.69   |\n",
      "------------------------\n",
      ", loss 915375.5625\n",
      "Model saved as saved_models/best_pacman_dqn_model_210.pth\n",
      "------------------------\n",
      "| episodes   |   211    |\n",
      "| score      |  55611.740000000005 |\n",
      "| epsilon    |  0.69   |\n",
      "------------------------\n",
      ", loss 734720.6875\n",
      "------------------------\n",
      "| episodes   |   212    |\n",
      "| score      |  39331.37999999999 |\n",
      "| epsilon    |  0.69   |\n",
      "------------------------\n",
      ", loss 741391.0000\n",
      "------------------------\n",
      "| episodes   |   213    |\n",
      "| score      |  46127.93 |\n",
      "| epsilon    |  0.68   |\n",
      "------------------------\n",
      ", loss 852560.5000\n",
      "------------------------\n",
      "| episodes   |   214    |\n",
      "| score      |  52969.32 |\n",
      "| epsilon    |  0.68   |\n",
      "------------------------\n",
      ", loss 793947.6250\n",
      "------------------------\n",
      "| episodes   |   215    |\n",
      "| score      |  53192.88 |\n",
      "| epsilon    |  0.68   |\n",
      "------------------------\n",
      ", loss 780025.3750\n",
      "------------------------\n",
      "| episodes   |   216    |\n",
      "| score      |  43483.35 |\n",
      "| epsilon    |  0.68   |\n",
      "------------------------\n",
      ", loss 1036271.5000\n",
      "------------------------\n",
      "| episodes   |   217    |\n",
      "| score      |  53761.51999999999 |\n",
      "| epsilon    |  0.68   |\n",
      "------------------------\n",
      ", loss 798892.5000\n",
      "------------------------\n",
      "| episodes   |   218    |\n",
      "| score      |  43824.12 |\n",
      "| epsilon    |  0.68   |\n",
      "------------------------\n",
      ", loss 843849.6250\n",
      "------------------------\n",
      "| episodes   |   219    |\n",
      "| score      |  47412.24999999999 |\n",
      "| epsilon    |  0.68   |\n",
      "------------------------\n",
      ", loss 770101.6250\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    env = PacMan()\n",
    "    \n",
    "    agent = DQNAgent(gamma=0.99, epsilon=1.0, batch_size=64, num_actions=4, \n",
    "                     eps_end=0.01, eps_dec=0.998, input_dims=(6, 50, 80), lr=0.001)\n",
    "    agent.q_eval.to(device)\n",
    "    agent.q_target.to(device)\n",
    "    \n",
    "    scores, eps_history = [], []\n",
    "    n_games = 220\n",
    "    best_score = -np.inf # initialize best score to a low value\n",
    "    save_folder = 'saved_models'\n",
    "    learn_interval = 10 # Call learn() every 10 steps\n",
    "    warmup_eps = 20 # Episodes before the agent starts learning\n",
    "    step_counter = 0 \n",
    "    \n",
    "    for i in range(n_games):\n",
    "        score = 0\n",
    "        done = False\n",
    "        observation, _ = env.reset()\n",
    "        loss = None\n",
    "        previous_loss = float('inf')\n",
    "        has_learned = False\n",
    "        while not done:\n",
    "            action = agent.choose_action(observation)\n",
    "            observation_, reward, done, truncated, info = env.step(action)\n",
    "            score += reward\n",
    "            \n",
    "            agent.store_transition(observation, action, reward, observation_, done)\n",
    "            \n",
    "            step_counter += 1\n",
    "            # Start learning only after warm-up period and learn periodically\n",
    "            if i > warmup_eps and step_counter % learn_interval == 0:\n",
    "                loss = agent.learn() # this is batch learning\n",
    "                has_learned = True\n",
    "            observation = observation_\n",
    "            # env.render()\n",
    "            \n",
    "        scores.append(score)\n",
    "        eps_history.append(agent.epsilon)\n",
    "        \n",
    "        # Calcualte average score over the last 100 games\n",
    "        avg_score = np.mean(scores[-100:])\n",
    "        \n",
    "        print('------------------------')\n",
    "        print(f'| episodes   |   {i}    |')\n",
    "        print(f'| score      |  {score} |')\n",
    "        print(f'| epsilon    |  {agent.epsilon:.2f}   |')\n",
    "        print('------------------------')\n",
    "        if loss is not None:\n",
    "            print(f', loss {loss:.4f}')\n",
    "        else: \n",
    "            print() # Just print a new line if loss is None\n",
    "            \n",
    "        if has_learned and loss < previous_loss:\n",
    "            agent.epsilon = max(agent.epsilon_end, agent.epsilon * agent.epsilon_decay)\n",
    "            # print(f\"Updated epsilon: {agent.epsilon}\") # debug statement\n",
    "        previous_loss = loss if loss is not None else previous_loss\n",
    "        # Save the model if the average score improves\n",
    "        # Save the model every 10 episodes\n",
    "        if has_learned and i % 10 == 0:\n",
    "            model_filename = f'{save_folder}/best_pacman_dqn_model_{i}.pth'\n",
    "            torch.save(agent.q_eval.state_dict(), model_filename)\n",
    "            print(f'Model saved as {model_filename}')\n",
    "\n",
    "    x = [i+1 for i in range(n_games)]\n",
    "    filename = 'pacman_plot.png'\n",
    "    plot_learning_curve(x, scores, eps_history, filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To load the model later\n",
    "# model_filename = 'pacman_dqn_model.pth'\n",
    "# agent.q_eval.load_state_dict(torch.load(model_filename))\n",
    "# agent.q_eval.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| episodes   |   219    |\n",
      "| score      |  47412.24999999999 |\n",
      "| epsilon    |  0.68   |\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "print('------------------------')\n",
    "print(f'| episodes   |   {i}    |')\n",
    "print(f'| score      |  {score} |')\n",
    "print(f'| epsilon    |  {agent.epsilon:.2f}   |')\n",
    "print('------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
