{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from mss import mss\n",
    "import pydirectinput\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from gymnasium import Env  # Change this import\n",
    "from gymnasium.spaces import Box, Discrete  # Change this import\n",
    "from gymnasium.utils import env_checker  # Import the environment checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PacMan(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.observation_space = Box(low=0, high=255, shape=(1,50,80), dtype=np.uint8)\n",
    "        self.action_space = Discrete(3)\n",
    "        \n",
    "        self.previous_lives = 2\n",
    "        self.current_lives = self.previous_lives\n",
    "        self.previous_score = 0\n",
    "        \n",
    "        self.pellet_address = 0x7268\n",
    "        self.file_path = \"pellet_count.txt\"\n",
    "        self.previous_pellet_count = self.read_pellet_count_from_file()\n",
    "        \n",
    "        self.cap = mss()\n",
    "        self.game_location = {'top':50, 'left':-2280, 'width':2000, 'height':1300}\n",
    "        self.score_location = {'top':380, 'left':-920, 'width':600, 'height':80} \n",
    "        self.done_location = {'top':520, 'left':-1800, 'width':450, 'height':70} \n",
    "        self.lives_location = {'top':1070, 'left':-902, 'width':600, 'height':200}\n",
    "        #self.done_location = {'top':508, 'left':-1810, 'width':450, 'height':80}     \n",
    "        \n",
    "    def read_pellet_count_from_file(self):\n",
    "        try:\n",
    "            with open(self.file_path, \"r\") as file:\n",
    "                return int(file.read().strip())\n",
    "        except (FileNotFoundError, ValueError):\n",
    "            return 0\n",
    "                 \n",
    "    # Action that is called to do something in the game\n",
    "    def step(self, action):\n",
    "        # Action key - 0 = Move Left, 1 = Move Right, 2 = Move Up, 3 = Move Down, 4 = No op\n",
    "        action_map = {\n",
    "            0: 'left',   # Move Left\n",
    "            1: 'right',  # Move Right\n",
    "            2: 'up',     # Move Up\n",
    "            3: 'down',   # Move Down\n",
    "            4: 'no_op'   # No operation (do nothing)\n",
    "        }\n",
    "        \n",
    "        if action != 4:\n",
    "            pydirectinput.press(action_map[action])\n",
    "            \n",
    "        current_pellet_count = self.read_pellet_count_from_file()\n",
    "        pellet_reward = self.get_pellet_reward(current_pellet_count)\n",
    "        \n",
    "        current_lives = self.get_lives()\n",
    "        life_penalty = 0\n",
    "        # Penalize only when a life is lost (and only once per life loss)\n",
    "        if current_lives < self.previous_lives:\n",
    "            life_penalty -= 500\n",
    "            self.previous_lives = current_lives # update previous lives \n",
    "            \n",
    "        reward = pellet_reward + life_penalty\n",
    "        \n",
    "        # Penalize heavily if all lives are lost\n",
    "        done = self.get_done()\n",
    "        # end_game_penalty = 0\n",
    "        # if done:\n",
    "        #     end_game_penalty -= 500\n",
    "        # else: \n",
    "        #     end_game_penalty -= 0\n",
    "            \n",
    "    \n",
    "        # Get the next observation\n",
    "        new_observation = self.get_observation()\n",
    "        \n",
    "        # Info dictionary\n",
    "        info = {} # needed for stablebaselines what it expects\n",
    "        \n",
    "        return new_observation, reward, done, False, info\n",
    "\n",
    "    \n",
    "    def render(self):\n",
    "        cv2.imshow('Game', np.array(self.cap.grab(self.game_location))[:,:,:3])\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            self.close()\n",
    "    \n",
    "    # Restart the game\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        pydirectinput.click(x=-890, y=374) # select game window\n",
    "        pydirectinput.press('f1') # Start state 1 save\n",
    "        self.previous_pellet_count = self.read_pellet_count_from_file()\n",
    "        return self.get_observation(), {}\n",
    "    \n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def get_observation(self):\n",
    "        # Get screen capture of game\n",
    "        raw = np.array(self.cap.grab(self.game_location))[:,:,:3]\n",
    "        #Grayscale\n",
    "        gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n",
    "        # Resize\n",
    "        resized = cv2.resize(gray, (80,50))\n",
    "        # Add channels first\n",
    "        channel = np.reshape(resized, (1,50,80))\n",
    "        return channel\n",
    "    \n",
    "    # Reward for eating pellets\n",
    "    def get_pellet_reward(self, current_pellet_count):\n",
    "        if current_pellet_count < self.previous_pellet_count:\n",
    "            reward = 30 \n",
    "            self.previous_pellet_count = current_pellet_count\n",
    "        else:\n",
    "            reward = 0    \n",
    "        return reward\n",
    "    \n",
    "    def get_score(self):\n",
    "        score_cap = np.array(self.cap.grab(self.score_location))[:,:,:3]\n",
    "        score_gray =cv2.cvtColor(score_cap, cv2.COLOR_BGR2GRAY)\n",
    "        _, score_thresh = cv2.threshold(score_gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Apply OCR on the processed image\n",
    "        score_text = pytesseract.image_to_string(score_thresh, config='digits')\n",
    "        \n",
    "        try:\n",
    "            score_value = int(score_text.strip())\n",
    "        except ValueError:\n",
    "            score_value = self.previous_score\n",
    "            \n",
    "        return score_cap, score_text\n",
    "    \n",
    "    def get_lives(self):   \n",
    "        # Capture the area where the lives are displayed\n",
    "        lives_cap = np.array(self.cap.grab(self.lives_location))[:,:,:3]\n",
    "        # Convert to grayscale\n",
    "        lives_gray = cv2.cvtColor(lives_cap, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Load pacman life icon template\n",
    "        pacman_life_template = cv2.imread('pacman_life_icon.png', 0)\n",
    "        \n",
    "        # Perform template matching\n",
    "        result = cv2.matchTemplate(lives_gray, pacman_life_template, cv2.TM_CCORR_NORMED)\n",
    "        threshold = 0.8\n",
    "        locations = np.where(result >= threshold)\n",
    "        \n",
    "        lives_value = len(list(zip(*locations[::-1])))\n",
    "        \n",
    "        # Determine number of lives\n",
    "        if lives_value == 684:\n",
    "            num_lives = 2\n",
    "        elif lives_value == 344:\n",
    "            num_lives = 1\n",
    "        else:\n",
    "            num_lives = 0\n",
    "            \n",
    "        return num_lives\n",
    "    \n",
    "    def get_done(self):\n",
    "        # Get the number of lives left \n",
    "        num_lives = self.get_lives()\n",
    "        return num_lives == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PacMan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8650752\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "current_pellet_count, obs, reward, done, truncated, info = env.step(env.action_space.sample())\n",
    "print(current_pellet_count)\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5963776"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pellet_count = env.read_pellet_count_from_file()\n",
    "pellet_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11927552"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_pellet_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = env.get_observation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e9d600160>"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cv2.cvtColor(env.get_observation()[0], cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e94bb8370>"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = PacMan()\n",
    "score_cap, score_text = env.get_score()\n",
    "plt.imshow(score_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oer\\n'"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0, 111, ...,   0,   0,   0],\n",
       "        [  0,   0, 111, ...,   0,   0,   0],\n",
       "        [  0,   0, 111, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0, 111, ...,   0,   0,   0],\n",
       "        [  0,   0, 111, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[592], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lives_cap, num_lives \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mget_lives()\n\u001b[0;32m      2\u001b[0m num_lives\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "lives_cap, num_lives = env.get_lives()\n",
    "num_lives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e9a12f100>"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(lives_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done = env.get_done()\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[473], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m#env.render()  # Render the game screen\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()  \u001b[38;5;66;03m# Sample random action\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Take the step\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Graceful exit if 'q' is pressed\u001b[39;00m\n\u001b[0;32m     10\u001b[0m         done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[468], line 28\u001b[0m, in \u001b[0;36mPacMan.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     19\u001b[0m action_map \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m,   \u001b[38;5;66;03m# Move Left\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Move Right\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;241m4\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_op\u001b[39m\u001b[38;5;124m'\u001b[39m   \u001b[38;5;66;03m# No operation (do nothing)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m }\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m---> 28\u001b[0m     \u001b[43mpydirectinput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpress\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Checking whether the game is done\u001b[39;00m\n\u001b[0;32m     31\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_done()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\CondaEnvs\\.conda\\dinoRL\\lib\\site-packages\\pydirectinput\\__init__.py:243\u001b[0m, in \u001b[0;36m_genericPyDirectInputChecks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    241\u001b[0m failSafeCheck()\n\u001b[0;32m    242\u001b[0m returnVal \u001b[38;5;241m=\u001b[39m wrappedFunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 243\u001b[0m \u001b[43m_handlePause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuncArgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_pause\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m returnVal\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\CondaEnvs\\.conda\\dinoRL\\lib\\site-packages\\pydirectinput\\__init__.py:232\u001b[0m, in \u001b[0;36m_handlePause\u001b[1;34m(_pause)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _pause:\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(PAUSE, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(PAUSE, \u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m--> 232\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPAUSE\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Game loop\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    #env.render()  # Render the game screen\n",
    "    action = env.action_space.sample()  # Sample random action\n",
    "    obs, reward, done, truncated, info = env.step(action)  # Take the step\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Graceful exit if 'q' is pressed\n",
    "        done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward for episode 0 is -100\n",
      "Total Reward for episode 1 is -40\n"
     ]
    }
   ],
   "source": [
    "# Play 10 games\n",
    "for episode in range(2):\n",
    "    obs = env.reset()\n",
    "    done =False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        obs, reward, done, truncated, info = env.step(env.action_space.sample())\n",
    "        total_reward += reward\n",
    "    print(f'Total Reward for episode {episode} is {total_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    \n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "            \n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "            \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = DQN('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, buffer_size=1200000, learning_starts=1000, exploration_initial_eps=1.0, exploration_final_eps=0.1, exploration_fraction=0.1, learning_rate = 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs\\DQN_2\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.8     |\n",
      "|    ep_rew_mean      | 130      |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 99       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 166      |\n",
      "|    exploration_rate | 0.689    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 173      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 183      |\n",
      "|    exploration_rate | 0.528    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 262      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.7     |\n",
      "|    ep_rew_mean      | 160      |\n",
      "|    exploration_rate | 0.433    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 315      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 156      |\n",
      "|    exploration_rate | 0.284    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 398      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 162      |\n",
      "|    exploration_rate | 0.147    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total_timesteps  | 474      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | 156      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total_timesteps  | 565      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 148      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total_timesteps  | 643      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 154      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 736      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 154      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 350      |\n",
      "|    total_timesteps  | 824      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 157      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 377      |\n",
      "|    total_timesteps  | 886      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | 153      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 399      |\n",
      "|    total_timesteps  | 936      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | 151      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 434      |\n",
      "|    total_timesteps  | 1016     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 6.44     |\n",
      "|    n_updates        | 3        |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 144      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 472      |\n",
      "|    total_timesteps  | 1107     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 10.1     |\n",
      "|    n_updates        | 26       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 142      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 507      |\n",
      "|    total_timesteps  | 1189     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 9.99     |\n",
      "|    n_updates        | 47       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 139      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 540      |\n",
      "|    total_timesteps  | 1265     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 11.4     |\n",
      "|    n_updates        | 66       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 136      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 579      |\n",
      "|    total_timesteps  | 1356     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 5.01     |\n",
      "|    n_updates        | 88       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 133      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 614      |\n",
      "|    total_timesteps  | 1439     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 6.04     |\n",
      "|    n_updates        | 109      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.7     |\n",
      "|    ep_rew_mean      | 134      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 641      |\n",
      "|    total_timesteps  | 1500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 6.58     |\n",
      "|    n_updates        | 124      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | 132      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 669      |\n",
      "|    total_timesteps  | 1566     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 7.54     |\n",
      "|    n_updates        | 141      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | 130      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 699      |\n",
      "|    total_timesteps  | 1635     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 8.67     |\n",
      "|    n_updates        | 158      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | 132      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 731      |\n",
      "|    total_timesteps  | 1708     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 4.8      |\n",
      "|    n_updates        | 176      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | 136      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 766      |\n",
      "|    total_timesteps  | 1790     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 8.84     |\n",
      "|    n_updates        | 197      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | 142      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 802      |\n",
      "|    total_timesteps  | 1873     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 5.45     |\n",
      "|    n_updates        | 218      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.3     |\n",
      "|    ep_rew_mean      | 143      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 827      |\n",
      "|    total_timesteps  | 1931     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 3.32     |\n",
      "|    n_updates        | 232      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 146      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 863      |\n",
      "|    total_timesteps  | 2016     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 4.62     |\n",
      "|    n_updates        | 253      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.3     |\n",
      "|    ep_rew_mean      | 142      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 899      |\n",
      "|    total_timesteps  | 2100     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 5.71     |\n",
      "|    n_updates        | 274      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 142      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 932      |\n",
      "|    total_timesteps  | 2178     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 3.69     |\n",
      "|    n_updates        | 294      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 142      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 956      |\n",
      "|    total_timesteps  | 2230     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 5.08     |\n",
      "|    n_updates        | 307      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 140      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 989      |\n",
      "|    total_timesteps  | 2308     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 7.31     |\n",
      "|    n_updates        | 326      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 139      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1023     |\n",
      "|    total_timesteps  | 2386     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 5.58     |\n",
      "|    n_updates        | 346      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 143      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1056     |\n",
      "|    total_timesteps  | 2464     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 4.03     |\n",
      "|    n_updates        | 365      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 149      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1090     |\n",
      "|    total_timesteps  | 2543     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 7.6      |\n",
      "|    n_updates        | 385      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | 146      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1119     |\n",
      "|    total_timesteps  | 2611     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 7.8      |\n",
      "|    n_updates        | 402      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 148      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1151     |\n",
      "|    total_timesteps  | 2685     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 5.01     |\n",
      "|    n_updates        | 421      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 147      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1180     |\n",
      "|    total_timesteps  | 2752     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 5.86     |\n",
      "|    n_updates        | 437      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | 150      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1210     |\n",
      "|    total_timesteps  | 2821     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 7.68     |\n",
      "|    n_updates        | 455      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | 151      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1242     |\n",
      "|    total_timesteps  | 2895     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 7.37     |\n",
      "|    n_updates        | 473      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 157      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1277     |\n",
      "|    total_timesteps  | 2977     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 4.13     |\n",
      "|    n_updates        | 494      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 158      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1311     |\n",
      "|    total_timesteps  | 3055     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 6.94     |\n",
      "|    n_updates        | 513      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 163      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1345     |\n",
      "|    total_timesteps  | 3134     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 6.22     |\n",
      "|    n_updates        | 533      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 168      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1381     |\n",
      "|    total_timesteps  | 3218     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 5.19     |\n",
      "|    n_updates        | 554      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 172      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1413     |\n",
      "|    total_timesteps  | 3294     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 6.42     |\n",
      "|    n_updates        | 573      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 172      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1446     |\n",
      "|    total_timesteps  | 3371     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 5.03     |\n",
      "|    n_updates        | 592      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 175      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1470     |\n",
      "|    total_timesteps  | 3425     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 5.72     |\n",
      "|    n_updates        | 606      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 178      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1504     |\n",
      "|    total_timesteps  | 3503     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 6.55     |\n",
      "|    n_updates        | 625      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 177      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1538     |\n",
      "|    total_timesteps  | 3582     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 7        |\n",
      "|    n_updates        | 645      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | 176      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1575     |\n",
      "|    total_timesteps  | 3669     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 8.84     |\n",
      "|    n_updates        | 667      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 173      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1604     |\n",
      "|    total_timesteps  | 3737     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 4.81     |\n",
      "|    n_updates        | 684      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | 173      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1638     |\n",
      "|    total_timesteps  | 3815     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 6        |\n",
      "|    n_updates        | 703      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | 174      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1672     |\n",
      "|    total_timesteps  | 3895     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 2.95     |\n",
      "|    n_updates        | 723      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 176      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1703     |\n",
      "|    total_timesteps  | 3966     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 8.46     |\n",
      "|    n_updates        | 741      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 177      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1732     |\n",
      "|    total_timesteps  | 4033     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 5.49     |\n",
      "|    n_updates        | 758      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | 182      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1771     |\n",
      "|    total_timesteps  | 4124     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 4.8      |\n",
      "|    n_updates        | 780      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | 184      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1803     |\n",
      "|    total_timesteps  | 4198     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 4.44     |\n",
      "|    n_updates        | 799      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | 184      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1837     |\n",
      "|    total_timesteps  | 4277     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 7.63     |\n",
      "|    n_updates        | 819      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | 182      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1867     |\n",
      "|    total_timesteps  | 4347     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 9.42     |\n",
      "|    n_updates        | 836      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | 177      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1903     |\n",
      "|    total_timesteps  | 4432     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 4.03     |\n",
      "|    n_updates        | 857      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 181      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1937     |\n",
      "|    total_timesteps  | 4510     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 7.48     |\n",
      "|    n_updates        | 877      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 180      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 1970     |\n",
      "|    total_timesteps  | 4587     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 4.49     |\n",
      "|    n_updates        | 896      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 182      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 2004     |\n",
      "|    total_timesteps  | 4667     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 6        |\n",
      "|    n_updates        | 916      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 183      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 2037     |\n",
      "|    total_timesteps  | 4744     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 6.46     |\n",
      "|    n_updates        | 935      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 182      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 2069     |\n",
      "|    total_timesteps  | 4818     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 6.11     |\n",
      "|    n_updates        | 954      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.3     |\n",
      "|    ep_rew_mean      | 184      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 2106     |\n",
      "|    total_timesteps  | 4904     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 3.22     |\n",
      "|    n_updates        | 975      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.3     |\n",
      "|    ep_rew_mean      | 182      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 2139     |\n",
      "|    total_timesteps  | 4981     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.01     |\n",
      "|    loss             | 3.09     |\n",
      "|    n_updates        | 995      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x23ebc219850>"
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=5000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x23e9390ebb0>"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load(os.path.join('train', 'best_model_5000'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward for episode 0 is 240\n",
      "Total Reward for episode 1 is 180\n",
      "Total Reward for episode 2 is 360\n",
      "Total Reward for episode 3 is 150\n",
      "Total Reward for episode 4 is 180\n",
      "Total Reward for episode 5 is 0\n",
      "Total Reward for episode 6 is 300\n",
      "Total Reward for episode 7 is 240\n",
      "Total Reward for episode 8 is 150\n",
      "Total Reward for episode 9 is 180\n"
     ]
    }
   ],
   "source": [
    "for episode in range(10):\n",
    "    obs, _ = env.reset()\n",
    "    done =False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, _, info = env.step(int(action))\n",
    "        total_reward += reward\n",
    "    print(f'Total Reward for episode {episode} is {total_reward}')\n",
    "    time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinoRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
